{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T22:57:16.473456Z",
     "start_time": "2020-11-15T22:57:16.461869Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import FineGym\n",
    "from torchvision import datasets, transforms\n",
    "from utils import augmentation\n",
    "from utils.utils import denorm\n",
    "from losses import compute_mask\n",
    "from models import Model\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import PIL\n",
    "device_ids = [0, 1]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4,5\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T22:57:19.300349Z",
     "start_time": "2020-11-15T22:57:19.292666Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "from torchvision.transforms import _transforms_video as transforms_video\n",
    "from torchvision.transforms import _functional_video as F\n",
    "\n",
    "class BottomCrop:\n",
    "    def __init__(self, size, consistent=True):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        img1 = imgmap[0]\n",
    "        w, h = img1[0].shape\n",
    "        th, tw = self.size\n",
    "        x1 = int(round(w - tw) -30)\n",
    "        y1 = int(round((h - th) / 2. + 20))\n",
    "        return F.crop(imgmap, x1, y1, tw, th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T22:57:19.472094Z",
     "start_time": "2020-11-15T22:57:19.469188Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#             BottomCrop(size=180, consistent=True),\n",
    "#             augmentation.Scale([128, 128]),\n",
    "#             augmentation.ToTensor(),\n",
    "#             augmentation.Normalize()\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T22:57:19.636845Z",
     "start_time": "2020-11-15T22:57:19.627875Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            augmentation.CenterCrop(size=128, consistent=True),\n",
    "            augmentation.ToTensor(),\n",
    "            augmentation.Normalize()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:15:25.828176Z",
     "start_time": "2020-11-15T23:15:25.821322Z"
    }
   },
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "args = Namespace(hyperbolic=True, \\\n",
    "                 hyperbolic_version=1, \\\n",
    "                 network_feature='resnet18', \\\n",
    "                 distance='squared', \\\n",
    "                 early_action=True, \\\n",
    "                 early_action_self=True, \\\n",
    "                 dataset='finegym', \\\n",
    "                 pred_step=1, \\\n",
    "                 seq_len=5, \\\n",
    "                 num_seq=6, \\\n",
    "                 ds=3, \\\n",
    "                 img_dim=128, \\\n",
    "                 batch_size=32, \\\n",
    "                 fp16=True, \\\n",
    "                 fp64_hyper=True, \\\n",
    "                 use_labels=False, \\\n",
    "                 n_classes=307, \\\n",
    "                 linear_input='features', \\\n",
    "                 hierarchical_labels=False, \\\n",
    "                 action_level_gt=True, \\\n",
    "                 num_workers=16, \\\n",
    "                 cross_gpu_score=True, \\\n",
    "                 feature_dim=256, \\\n",
    "                 viz=True, \\\n",
    "                 not_track_running_stats=True, \\\n",
    "                 final_2dim=False, \\\n",
    "                 no_spatial=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:15:26.742838Z",
     "start_time": "2020-11-15T23:15:26.294918Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = FineGym(mode='test',\n",
    "                 path_dataset='/proj/vondrick/datasets/FineGym',\n",
    "                 transform=transform,\n",
    "                 seq_len=5,  # given duration distribution, we should aim for ~1.5 seconds (around 7-8 frames at 5 fps)\n",
    "                 num_seq=6,\n",
    "                 unit_test=False,\n",
    "                 return_label=False,\n",
    "                  hierarchical_label=False,\n",
    "                  action_level_gt=False, return_idx=True)\n",
    "dataloader = data.DataLoader(dataset,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=args.num_workers,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:15:27.829353Z",
     "start_time": "2020-11-15T23:15:26.744529Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e8f3549c064d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vpath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'idx_block'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "dataset[0][0]['vpath'], dataset[0][0]['idx_block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:15:27.833432Z",
     "start_time": "2020-11-15T23:15:27.831142Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '/proj/vondrick/didac/code/DPC/logs/log_earlyaction_linear_finegym_kinetics_fromfinetune_lr2/20201101_192504/model/model_best_epoch91.pth.tar'\n",
    "# model_path = '/proj/vondrick/didac/code/DPC/logs/log_earlyaction_linear_finegym_64d_v2/20201112_113024/model/model_best_epoch94.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:15:28.322464Z",
     "start_time": "2020-11-15T23:15:27.834911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (backbone): ResNet2d3d_full(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock2d(\n",
       "          (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "        (1): BasicBlock2d(\n",
       "          (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock2d(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock2d(\n",
       "          (conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock3d(\n",
       "          (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock3d(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock3d(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock3d(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (adapt_dim): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (hyperbolic_linear): MobiusLinear(\n",
       "      , hyperbolic_bias=True\n",
       "      (ball): PoincareBall manifold\n",
       "    )\n",
       "    (agg): ConvGRU(\n",
       "      (ConvGRUCell_00): ConvGRUCell(\n",
       "        (reset_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (update_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (out_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (cell_list): ModuleList(\n",
       "        (0): ConvGRUCell(\n",
       "          (reset_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (update_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (out_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (network_pred): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (time_index): Embedding(6, 256)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(args).cuda()\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:15:28.328718Z",
     "start_time": "2020-11-15T23:15:28.324194Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# video = 'rrrgsW--AE8'\n",
    "video = 'Z2T9B4qExzk'\n",
    "idx_list = []\n",
    "for idx in range(len(dataset.idx2clipidx)):\n",
    "    if video in dataset.idx2clipidx[idx]:\n",
    "        idx_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:15:31.337302Z",
     "start_time": "2020-11-15T23:15:29.591500Z"
    }
   },
   "outputs": [],
   "source": [
    "all_video = []\n",
    "all_pred = []\n",
    "all_feature = []\n",
    "all_vpath = []\n",
    "all_idx_block = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:29.957Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6d885db673424da5d130292837d9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=104.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-75a1a561ae11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_seq\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, (input_dict, label) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        input_seq = input_dict['t_seq'].cuda()\n",
    "        pred, feature, size = model(input_seq)\n",
    "        pred = pred.reshape(args.batch_size, args.num_seq - args.pred_step, 16, args.feature_dim)[:, :, 5, :].detach().cpu()\n",
    "        feature = feature[:, :, :, 1, 1].detach().cpu()\n",
    "        all_pred.append(pred)\n",
    "        all_feature.append(feature)\n",
    "        all_video.append(input_seq.cpu())\n",
    "        all_vpath.append(input_dict['vpath'])\n",
    "#         all_idx_block.append(input_dict['idx_block'])\n",
    "        del input_seq, pred, feature, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:30.352Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = torch.stack(all_pred).reshape(-1, args.feature_dim)\n",
    "feature = torch.stack(all_feature).reshape(-1, args.feature_dim)\n",
    "videos = torch.stack(all_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:30.705Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = torch.cat(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:30.882Z"
    }
   },
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:31.043Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_norm = torch.norm(pred, dim=2)\n",
    "uncertain_rank = pred_norm[:, -1].argsort(descending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:31.227Z"
    }
   },
   "outputs": [],
   "source": [
    "all_vpath_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:32.355Z"
    }
   },
   "outputs": [],
   "source": [
    "# permute axis in returned vpath [num_videos, num_seq]\n",
    "all_vpath_processed = []\n",
    "for batch_ind in range(len(all_vpath)):\n",
    "    batch_list = []\n",
    "    for vpath_ind in range(len(all_vpath[0][0])):\n",
    "        step_list = []\n",
    "        for step_ind in range(len(all_vpath[0])):\n",
    "            step_list.append(all_vpath[batch_ind][step_ind][vpath_ind])\n",
    "        batch_list.append(step_list)\n",
    "    all_vpath_processed.extend(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:54.501Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_finegym(vpath, rank, index):\n",
    "    images = []\n",
    "    path_list = vpath[index]\n",
    "    for i in range(len(path_list)):\n",
    "        video, audio, info = torchvision.io.read_video(path_list[i], start_pts=0, end_pts=None, pts_unit='sec')\n",
    "        for frame in video:\n",
    "            if i == len(path_list) - 1:\n",
    "                im = frame.numpy()\n",
    "                im[:, :10] = np.array([100, 100, 255])\n",
    "                im[:10, :] = np.array([100, 100, 255])\n",
    "                im[:, -10:] = np.array([100, 100, 255])\n",
    "                im[-10:, :] = np.array([100, 100, 255])\n",
    "                images.append(PIL.Image.fromarray(im))\n",
    "        else:\n",
    "            for frame in video:\n",
    "                images.append(PIL.Image.fromarray(frame.numpy()))\n",
    "        gif_path = os.path.join('uncertain_gif', 'finegym', 'uncertain_rank_%d_index_%d.gif' % (rank, index))\n",
    "        images[0].save(gif_path, format='GIF', append_images=images[1:], save_all=True, duration=50, loop=0)\n",
    "    return images, gif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:54.826Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_gif(gif_path):\n",
    "    with open(gif_path,'rb') as f:\n",
    "        display(Image(width = 600, height = 400, data=f.read(), format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T18:42:26.369374Z",
     "start_time": "2020-11-15T18:42:26.367101Z"
    }
   },
   "source": [
    "# save gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:55.769Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    rank = i\n",
    "    images, gif_path = plot_finegym(all_vpath_processed, rank, uncertain_rank[rank])\n",
    "#     display_gif(gif_path)\n",
    "    print('rank: %d' % rank)\n",
    "    print('index: %d' % uncertain_rank[rank])\n",
    "    print('radius: %f' % pred_norm[uncertain_rank[rank], -1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-15T23:15:56.275Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    rank = len(uncertain_rank) - i - 1\n",
    "    images, gif_path = plot_finegym(all_vpath_processed, uncertain_rank[rank], rank)\n",
    "#     display_gif(gif_path)\n",
    "    print('rank: %d' % rank)\n",
    "    print('index: %d' % uncertain_rank[rank])\n",
    "    print('radius: %f' % pred_norm[uncertain_rank[rank], -1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
