{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:38.942534Z",
     "start_time": "2020-10-29T21:20:37.031277Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models import Model\n",
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.hyp_cone_utils import cone_distance_sum\n",
    "from utils.poincare_distance import poincare_distance\n",
    "from losses import compute_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:38.957279Z",
     "start_time": "2020-10-29T21:20:38.944723Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_mask(args, sizes, B):\n",
    "    if args.use_labels:\n",
    "        return None, None  # No need to compute mask\n",
    "\n",
    "    last_size, size_gt, size_pred = sizes[0]\n",
    "\n",
    "    # mask meaning: -2: omit, -1: temporal neg (hard), 0: easy neg, 1: pos, -3: spatial neg\n",
    "    mask = torch.zeros((B, size_pred, last_size ** 2, B, size_gt, last_size ** 2), dtype=torch.int8, requires_grad=False).detach().cuda()\n",
    "\n",
    "    mask[torch.arange(B), :, :, torch.arange(B), :, :] = -3  # spatial neg\n",
    "\n",
    "    if args.early_action_self:\n",
    "        pass  # Here NO temporal neg! All steps try to predict the last one\n",
    "    else:\n",
    "        for k in range(B):\n",
    "            mask[k, :, torch.arange(last_size ** 2), k, :, torch.arange(last_size ** 2)] = -1  # temporal neg\n",
    "\n",
    "    tmp = mask.permute(0,2,1,3,5,4).reshape(B * last_size ** 2, size_pred, B * last_size ** 2, size_gt)\n",
    "\n",
    "    if args.early_action_self:\n",
    "        tmp[torch.arange(B * last_size ** 2), :, torch.arange(B * last_size ** 2)] = 1  # pos\n",
    "    else:\n",
    "        assert size_gt == size_pred\n",
    "        for j in range(B * last_size ** 2):\n",
    "            tmp[j, torch.arange(size_pred), j, torch.arange(size_gt)] = 1  # pos\n",
    "\n",
    "    mask = tmp.view(B, last_size ** 2, size_pred, B, last_size ** 2, size_gt).permute(0, 2, 1, 3, 5, 4)\n",
    "\n",
    "    # Now, given task mask as input, compute the target for contrastive loss\n",
    "    if mask is None:\n",
    "        return None, None\n",
    "    # dot product is computed in parallel gpus, so get less easy neg, bounded by batch size in each gpu'''\n",
    "    # mask meaning: -2: omit, -1: temporal neg (hard), 0: easy neg, 1: pos, -3: spatial neg\n",
    "    (B, NP, SQ, B2, NS, _) = mask.size()  # [B, P, SQ, B, N, SQ]\n",
    "    target = mask == 1\n",
    "    target.requires_grad = False\n",
    "    return target, (B, B2, NS, NP, SQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:38.968013Z",
     "start_time": "2020-10-29T21:20:38.958791Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "device_ids = [0, 1]\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:39.043198Z",
     "start_time": "2020-10-29T21:20:39.041056Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '/proj/vondrick/didac/code/DPC/logs/log_train_dpc_hyper_v1_poincare_kinetics/20201019_195227/model/model_best_epoch159.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:39.330682Z",
     "start_time": "2020-10-29T21:20:39.327702Z"
    }
   },
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:39.562495Z",
     "start_time": "2020-10-29T21:20:39.557847Z"
    }
   },
   "outputs": [],
   "source": [
    "args = Namespace(hyperbolic=True, \\\n",
    "                 hyperbolic_version=1, \\\n",
    "                 network_feature='resnet18', \\\n",
    "                 distance='squared', \\\n",
    "                 early_action=False, \\\n",
    "                 early_action_self=False, \\\n",
    "                 dataset='k600', \\\n",
    "                 pred_step=3, \\\n",
    "                 seq_len=5, \\\n",
    "                 num_seq=8, \\\n",
    "                 ds=3, \\\n",
    "                 img_dim=128, \\\n",
    "                 batch_size=32, \\\n",
    "                 fp16=True, \\\n",
    "                 fp64_hyper=True, \\\n",
    "                 use_labels=False, \\\n",
    "                 n_classes=0, \\\n",
    "                 linear_input=True, \\\n",
    "                 hierarchical_labels=False, \\\n",
    "                 action_level_gt=False, \\\n",
    "                 num_workers=16, \\\n",
    "                 cross_gpu_score=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:43.265528Z",
     "start_time": "2020-10-29T21:20:39.850857Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:43.488105Z",
     "start_time": "2020-10-29T21:20:43.267614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (backbone): ResNet2d3d_full(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock2d(\n",
       "          (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "        (1): BasicBlock2d(\n",
       "          (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock2d(\n",
       "          (conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock2d(\n",
       "          (conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock3d(\n",
       "          (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock3d(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock3d(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock3d(\n",
       "          (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (hyperbolic_linear): MobiusLinear(\n",
       "      , hyperbolic_bias=True\n",
       "      (ball): PoincareBall manifold\n",
       "    )\n",
       "    (agg): ConvGRU(\n",
       "      (ConvGRUCell_00): ConvGRUCell(\n",
       "        (reset_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (update_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (out_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (cell_list): ModuleList(\n",
       "        (0): ConvGRUCell(\n",
       "          (reset_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (update_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (out_gate): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (network_pred): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:20:59.372733Z",
     "start_time": "2020-10-29T21:20:58.618911Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from utils import augmentation\n",
    "from datasets import Kinetics600_full_3d\n",
    "from torch.utils import data\n",
    "transform = transforms.Compose([\n",
    "            augmentation.RandomSizedCrop(size=args.img_dim, consistent=True, p=1.0),\n",
    "            augmentation.RandomHorizontalFlip(consistent=True),\n",
    "            augmentation.RandomGray(consistent=False, p=0.5),\n",
    "            augmentation.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.25, p=1.0),\n",
    "            augmentation.ToTensor(),\n",
    "            augmentation.Normalize()\n",
    "        ])\n",
    "dataset = Kinetics600_full_3d(mode='test',\n",
    "                              transform=transform,\n",
    "                              seq_len=args.seq_len,\n",
    "                              num_seq=args.num_seq,\n",
    "                              downsample=5,\n",
    "                              return_label=False,\n",
    "                              vis=True)\n",
    "dataloader = data.DataLoader(dataset,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=args.num_workers,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model loading and dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:23:56.176800Z",
     "start_time": "2020-10-29T21:23:44.203796Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx, (input_dict, label) = next(enumerate(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:24:44.695339Z",
     "start_time": "2020-10-29T21:24:44.691031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, torch.Size([32, 40]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_dict['vpath']), input_dict['idx_block'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:28:49.499867Z",
     "start_time": "2020-10-29T20:28:41.235Z"
    }
   },
   "outputs": [],
   "source": [
    "input_seq = input_seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:28:49.500939Z",
     "start_time": "2020-10-29T20:28:41.237Z"
    }
   },
   "outputs": [],
   "source": [
    "pred, feature_dist, sizes = model(input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spatial pooling embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:28:49.501796Z",
     "start_time": "2020-10-29T20:28:41.238Z"
    }
   },
   "outputs": [],
   "source": [
    "target, (B, B2, NS, NP, SQ) = compute_mask(args, sizes, args.batch_size)\n",
    "_, D = pred.shape\n",
    "pred = pred.reshape(B, NP, SQ, D)\n",
    "feature_dist = feature_dist.reshape(B, NS, SQ, D)\n",
    "pred_pooled = torch.mean(pred, dim=2).reshape(-1, D)\n",
    "feature_dist_pooled = torch.mean(feature_dist, dim=2).reshape(-1, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:28:49.502739Z",
     "start_time": "2020-10-29T20:28:41.239Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_pooled = pred_pooled.reshape(B, NP, D)\n",
    "feature_dist_pooled = feature_dist_pooled.reshape(B, NS, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:28:49.503621Z",
     "start_time": "2020-10-29T20:28:41.240Z"
    }
   },
   "outputs": [],
   "source": [
    "# poincare_distance(pred_pooled, feature_dist_pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect all feature_dist from Kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T20:28:49.504671Z",
     "start_time": "2020-10-29T20:28:41.241Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:25:13.055922Z",
     "start_time": "2020-10-29T21:25:13.052833Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "all_preds = []\n",
    "all_vpaths = []\n",
    "all_idx_blocks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:26:19.098652Z",
     "start_time": "2020-10-29T21:25:14.776499Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03360d792e1845bd963f8c510c12376a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11766.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../backbone/hyrnn_nets.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k = torch.tensor(k)\n",
      "Traceback (most recent call last):\n",
      "  File \"/proj/vondrick/ruoshi/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/proj/vondrick/ruoshi/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/proj/vondrick/ruoshi/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with image in path /local/vondrick/ruoshi/k600/extracted_frames/train/arguing/25fps5EddqmM0QJY_000032_000042/image_00199.jpg\n",
      "Error with image in path /local/vondrick/ruoshi/k600/extracted_frames/train/arguing/25fps4O-6WE8flyg_000025_000035/image_00091.jpg\n",
      "Error with image in path /local/vondrick/ruoshi/k600/extracted_frames/train/arguing/25fpsOGYgdjNeoD8_000020_000030/image_00062.jpg\n",
      "Error with image in path /local/vondrick/ruoshi/k600/extracted_frames/train/archery/25fps1Y3VfZz-sYc_000029_000039/image_00041.jpg\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8d6fbd5f3456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, (input_dict, label) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        input_seq = input_dict['t_seq'].cuda()\n",
    "        pred, feature_dist, sizes = model(input_seq)\n",
    "        target, (B, B2, NS, NP, SQ) = compute_mask(args, sizes, args.batch_size)\n",
    "        _, D = pred.shape\n",
    "        pred = pred.reshape(B, NP, SQ, D)\n",
    "        feature_dist = feature_dist.reshape(B, NS, SQ, D)\n",
    "        pred_pooled = torch.mean(pred, dim=2).reshape(-1, D)\n",
    "        feature_dist_pooled = torch.mean(feature_dist, dim=2).reshape(-1, D)\n",
    "        del pred, feature_dist\n",
    "        pred_pooled = pred_pooled.reshape(B, NP, D)\n",
    "        feature_dist_pooled = feature_dist_pooled.reshape(B, NS, D)\n",
    "        all_features.append(feature_dist_pooled.cpu().detach())\n",
    "        all_preds.append(pred_pooled.cpu().detach())\n",
    "        all_vpaths.extend(input_dict['vpath'])\n",
    "        all_idx_blocks.append(input_dict['idx_block'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:26:21.234270Z",
     "start_time": "2020-10-29T21:26:21.161414Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features = torch.cat(all_features)\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_idx_blocks = torch.cat(all_idx_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:26:41.942709Z",
     "start_time": "2020-10-29T21:26:41.938575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5600, 40]),\n",
       " torch.Size([5600, 3, 256]),\n",
       " torch.Size([5600, 3, 256]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_idx_blocks.shape, all_features.shape, all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:34:18.699723Z",
     "start_time": "2020-10-29T21:34:18.696476Z"
    }
   },
   "outputs": [],
   "source": [
    "features_info = {'feature': all_features, 'pred': all_preds, 'vpath': all_vpaths, 'idx_block': all_idx_blocks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T22:59:01.159318Z",
     "start_time": "2020-10-29T22:59:00.870249Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# model_path = args.pretrain\n",
    "base_path = '/'.join(model_path.split('/')[:-2])\n",
    "embedding_path = os.path.join(base_path, 'embeds')\n",
    "if not os.path.exists(embedding_path):\n",
    "    os.makedirs(embedding_path)\n",
    "\n",
    "f = open(os.path.join(embedding_path, model_path.split('/')[-1][:-8] + '_embeds.pkl'),'wb')\n",
    "pickle.dump(features_info,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T21:32:46.242475Z",
     "start_time": "2020-10-29T21:32:46.238378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/proj/vondrick/didac/code/DPC/logs/log_train_dpc_hyper_v1_poincare_kinetics/20201019_195227'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(model_path.split('/')[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T22:57:11.696687Z",
     "start_time": "2020-10-29T22:57:11.692371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_best_epoch159embeds'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path.split('/')[-1][:-8] + '_embeds.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
